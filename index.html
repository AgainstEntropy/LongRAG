
<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <meta name="description" content="LongRAG">
  <meta name="keywords" content="Retrieval Augment Generation">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>LongRAG</title>

  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bulma@0.9.1/css/bulma.min.css">
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link href="https://fonts.googleapis.com/icon?family=Material+Icons" rel="stylesheet">

  <link rel="icon" type="image/x-icon" href="static/images/LongRAG_icon.png">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/js/all.min.js"></script>
  <script type="module" src="https://gradio.s3-us-west-2.amazonaws.com/4.16.0/gradio.js"></script>
</head>

<style>
  .expandable-card .card-text-container {
    max-height: 200px;
    overflow-y: hidden;
    position: relative;
  }

  .expandable-card.expanded .card-text-container {
    max-height: none;
  }

  .expand-btn {
    position: relative;
    display: none;
    background-color: rgba(255, 255, 255, 0.8);
    /* margin-top: -20px; */
    /* justify-content: center; */
    color: #510c75;
    border-color: transparent;
  }

  .expand-btn:hover {
    background-color: rgba(200, 200, 200, 0.8);
    text-decoration: none;
    border-color: transparent;
    color: #510c75;
  }

  .expand-btn:focus {
    outline: none;
    text-decoration: none;
  }

  .expandable-card:not(.expanded) .card-text-container:after {
    content: "";
    position: absolute;
    bottom: 0;
    left: 0;
    width: 100%;
    height: 90px;
    background: linear-gradient(rgba(255, 255, 255, 0.2), rgba(255, 255, 255, 1));
  }

  .expandable-card:not(.expanded) .expand-btn {
    margin-top: -40px;
  }

  .card-body {
    padding-bottom: 5px;
  }

  .vertical-flex-layout {
    justify-content: center;
    align-items: center;
    height: 100%;
    display: flex;
    flex-direction: column;
    gap: 5px;
  }

  .figure-img {
    max-width: 100%;
    height: auto;
  }

  .adjustable-font-size {
    font-size: calc(0.5rem + 2vw);
  }

  .chat-history {
    flex-grow: 1;
    overflow-y: auto;
    /* overflow-x: hidden; */
    padding: 5px;
    border-bottom: 1px solid #ccc;
    margin-bottom: 10px;
  }

  #gradio pre {
    background-color: transparent;
  }
</style>

<body>

<!----------------------------------------- Title and Authors. --------------------------------------------------->
<section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">LongRAG: Enhancing Retrieval-Augmented Generation with Long-context LLMs</h1>
              <div class="is-size-5 publication-authors">
                  <span class="author-block">
                    <a href="https://xmhzz2018.github.io/" style="color:#008AD7;font-weight:normal;">Ziyan Jiang</a>,
                  </span>
                  <span class="author-block">
                    <a href="https://mxueguang.github.io/" style="color:#008AD7;font-weight:normal;">Xueguang Ma</a>,
                  </span>
                  <span class="author-block">
                    <a href="https://wenhuchen.github.io/" style="color:#008AD7;font-weight:normal;">Wenhu Chen</a>
                  </span>
              </div>

            <div class="is-size-5 publication-authors">
              <span class="author-block"><b style="color:#008AD7; font-weight:normal">&#x25B6 </b> University of Waterloo</b></span>
            </div>

            <div class="column has-text-centered">
              <div class="publication-links">
                <span class="link-block">
                  <a href="https://arxiv.org/abs/2406.15319" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="ai ai-arxiv"></i>
                    </span>
                    <span>arXiv</span>
                  </a>
                </span>

                <span class="link-block">
                  <a href="https://github.com/TIGER-AI-Lab/LongRAG/" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>

                <span class="link-block">
                  <a href="https://huggingface.co/datasets/TIGER-Lab/LongRAG" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      ðŸ¤—
                    </span>
                    <span> Dataset</span>
                  </a>
                </span>

                <span class="link-block">
                  <a href="https://x.com/WenhuChen/status/1805278871786340644"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon has-text-white">
                    <i class="fab fa-twitter"></i>
                  </span>
                  <span>Twitter</span>
                </a>
              </span>

              </div>
            </div>

          </div>
        </div>
      </div>
    </div>
  </section>


<!-- Paper abstract -->
<section class="hero is-light is-small">
  <div class="hero-body has-text-centered">
    <h2 class="title is-3">
      Abstract</h2>
  </div>
</section>

<section class="hero is-small">
    <div class="hero-body">
        <div class="container is-max-desktop">
            <div class="columns is-centered">
                <div class="column has-text-centered">
                    <div class="content has-text-justified">
                        <p>

                          In traditional RAG framework, the basic retrieval units are normally short. The common retrievers like DPR normally work with 100-word Wikipedia paragraphs.
                          Such a design forces the retriever to search over a large corpus to find the "needle" unit. In contrast, the readers only need to extract answers from the
                          short retrieved units. Such an imbalanced heavy retriever and light reader design can lead to sub-optimal performance. In order to alleviate the imbalance,
                          we propose a new framework LongRAG, consisting of a "long retriever" and a "long reader". LongRAG processes the entire Wikipedia into 4K-token units, which is
                          30x longer than before. By increasing the unit size, we significantly reduce the total units from 22M to 600K. This significantly lowers the burden of retriever,
                          which leads to a remarkable retrieval score: answer recall@1=71% on NQ (previously 52%) and answer recall@2=72% (previously 47%) on HotpotQA (full-wiki). Then
                          we feed the top-k retrieved units (â‰ˆ 30K tokens) to an existing long-context LLM to perform zero-shot answer extraction. Without requiring any training, LongRAG
                          achieves an EM of 62.7% on NQ and 64.3% on HotpotQA (full-wiki), which is on par with the SoTA model. Our study offers insights into the future roadmap for combining
                          RAG with long-context LLMs. <br>


                        </p>
                    </div>
                </div>
            </div>
        </div>
    </div>
</section>
<!-- End paper abstract -->



<!-- Image carousel -->
<section class="hero">
    <div class="hero-body">
        <div class="container is-max-desktop">
            <div class="columns is-centered has-text-centered">
                <div class="column is-four-fifths">
                    <div class="item">
                        <!-- Your image here -->
                        <img src="static/images/teaser.png" alt="Traditional RAG vs. LongRAG." />
                        <h2 class="subtitle has-text-centered">
                            Figure 1: Traditional RAG vs. LongRAG.
                        </h2>
                        <p style="text-align: left;">
                            Traditional RAG operates on short retrieval units, where retriever needs to scan over massive amount of units to find the relevant piece. In contrast, LongRAG
                            operates on long retrieval units (30x longer). Retriever has a much less workload, which significantly boosts the recall score. LongRAG fully exploits the ability
                            of long-context language models (reader) to achieve strong performance.
                        </p>
                    </div>
                </div>
            </div>
        </div>
    </div>
</section>
<!-- End image carousel -->



<!-- Framework -->
  <section class="hero is-light is-small">
  <div class="hero-body has-text-centered">
    <h2 class="title is-3">
      Framework</h2>
  </div>
  </section>

<section class="hero is-small">
    <div class="hero-body">
        <div class="container is-max-desktop">
            <div class="columns is-centered has-text-centered">
                <div class="column is-four-fifths">
                    <div class="item">
                        <!-- Your image here -->
                        <img src="static/images/framework.png" alt="MY ALT TEXT" />
                        <h2 class="subtitle has-text-centered">
                            Figure 2: Our proposed LongRAG framework is comprised of two components: the Long Retriever and the Long Reader.
                        </h2>
                        <p style="text-align: left;">
                             On the left side, it shows that the long retrieval unit is grouped by Wikipedia documents through hyperlinks. Each retrieval unit contains an average of 4K tokens,
                            corresponding to multiple related documents. On the right side, it shows a multi-hop question answer test case from HotpotQA. The final result can be achieved by
                            using only a few retrieval units, which is then fed into a long reader.
                        </p>
                    </div>
                </div>
            </div>
        </div>
    </div>
</section>
<!-- End framework -->



<!-- Retrieval results -->
<section class="hero is-light is-small">
  <div class="hero-body has-text-centered">
    <h2 class="title is-3">
      Retrieval Results</h2>
  </div>
</section>


<section class="hero is-small">
    <div class="hero-body">
        <div class="container is-max-desktop">
            <div class="columns is-centered has-text-centered">
                <div class="column is-four-fifths">
                      <div class="container">
                        <table class="table is-bordered is-narrow is-hoverable is-fullwidth">
                          <thead>
                            <tr>
                              <th rowspan="2">Retrieval Unit</th>
                              <th rowspan="2">Corpus Size</th>
                              <th rowspan="2">Num of Retrieval Units</th>
                              <th colspan="2">Average Num of Tokens</th>
                              <th rowspan="2">Answer Recall (AR)</th>
                            </tr>
                            <tr>
                              <th>Corpus</th>
                              <th>Test Set</th>
                            </tr>
                          </thead>
                          <tbody>
                            <tr>
                              <td rowspan="3">Passage</td>
                              <td rowspan="3">22M</td>
                              <td>1</td>
                              <td>120</td>
                              <td>130</td>
                              <td>52.24</td>
                            </tr>
                            <tr>
                              <td>100</td>
                              <td>12K</td>
                              <td>14K</td>
                              <td>89.92</td>
                            </tr>
                            <tr>
                              <td>200</td>
                              <td>24K</td>
                              <td>28K</td>
                              <td>91.30</td>
                            </tr>
                            <tr>
                              <td rowspan="3">Document</td>
                              <td rowspan="3">3M</td>
                              <td>1</td>
                              <td>820</td>
                              <td>4K</td>
                              <td>69.45</td>
                            </tr>
                            <tr>
                              <td>5</td>
                              <td>4K</td>
                              <td>18K</td>
                              <td>85.37</td>
                            </tr>
                            <tr>
                              <td>10</td>
                              <td>8K</td>
                              <td>34K</td>
                              <td>88.12</td>
                            </tr>
                            <tr>
                              <td rowspan="3">Grouped Documents</td>
                              <td rowspan="3">600K</td>
                              <td>1</td>
                              <td>4K</td>
                              <td>6K</td>
                              <td>71.69</td>
                            </tr>
                            <tr>
                              <td>4</td>
                              <td>16K</td>
                              <td>25K</td>
                              <td>86.30</td>
                            </tr>
                            <tr>
                              <td>8</td>
                              <td>32K</td>
                              <td>50K</td>
                              <td>88.53</td>
                            </tr>
                          </tbody>
                        </table>
                      </div>
                        <p style="text-align: left;">
                            Employing a long-context retriever (with an average number of tokens for each retrieval unit up to 6K) compresses the corpus size by up to 30 times (from 22M to
                            600K), enhancing top-1 answer recall by approximately 20 points (from 52.24 to 71.69). Furthermore, long-context retrieval requires significantly fewer retrieval
                            units (10 times fewer) to achieve comparable results. Therefore, integrating long-context retrieval significantly alleviates the burden on the retriever model.
                        </p>
                    </div>

                     <div class="container">
                        <table class="table is-bordered is-narrow is-hoverable is-fullwidth">
                          <thead>
                            <tr>
                              <th rowspan="2">Retrieval Unit</th>
                              <th rowspan="2">Corpus Size</th>
                              <th rowspan="2">Num of Retrieval Units</th>
                              <th colspan="2">Average Num of Tokens</th>
                              <th rowspan="2">Recall (R)</th>
                              <th rowspan="2">Answer Recall (AR)</th>
                            </tr>
                            <tr>
                              <th>Corpus</th>
                              <th>Test Set</th>
                            </tr>
                          </thead>
                          <tbody>
                            <tr>
                              <td rowspan="3">Document</td>
                              <td rowspan="3">5.2M</td>
                              <td>2</td>
                              <td>130</td>
                              <td>200</td>
                              <td>30.01</td>
                              <td>47.75</td>
                            </tr>
                            <tr>
                              <td>100</td>
                              <td>6.5K</td>
                              <td>10K</td>
                              <td>74.84</td>
                              <td>84.67</td>
                            </tr>
                            <tr>
                              <td>200</td>
                              <td>13K</td>
                              <td>20K</td>
                              <td>79.68</td>
                              <td>88.34</td>
                            </tr>
                            <tr>
                              <td rowspan="2">Grouped Documents</td>
                              <td rowspan="2">500K</td>
                              <td>2</td>
                              <td>1K</td>
                              <td>8K</td>
                              <td>56.30</td>
                              <td>72.49</td>
                            </tr>
                            <tr>
                              <td>8</td>
                              <td>4K</td>
                              <td>29K</td>
                              <td>74.71</td>
                              <td>84.40</td>
                            </tr>
                          </tbody>
                        </table>
                         <p style="text-align: left;">
                             Similar to the findings on NQ, a long-context retrieval could significantly alleviate the burden on the retriever component within the entire RAG framework.
                         </p>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </div>
</section>
<!-- End retrieval results -->


  <section class="hero is-light is-small">
  <div class="hero-body has-text-centered">
    <h2 class="title is-3">
      QA Results</h2>
  </div>
  </section>
  <br><br>
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-four-fifths has-text-centered">

          <div class="model-labels-container is-size-5">

            <span style="background-color: rgba(255, 99, 132, 0.15);padding: 5px 10px;">Closed-Book</span>
            <span style="background-color: rgba(54, 162, 235, 0.15);padding: 5px 10px;">Fully-supervised RAG</span>
            <span style="background-color: rgba(75, 192, 192, 0.15);padding: 5px 10px;">No Fine-tuning RAG</span>

            <p></p>
          </div>

          <table class="table is-bordered is-three-fifths">
          <thead>
            <tr style="background-color: rgba(211, 211, 211, 0.5);">
              <th>Method</th>
              <th>EM(Exact Match Rate)</th>
            </tr>
          </thead>
          <tbody>

          <tr style="background-color: rgba(255, 99, 132, 0.15);">
              <td><a href="https://arxiv.org/abs/2303.08774">GPT-4-Turbo</a></td><td>41.2</td></tr>

          <tr style="background-color: rgba(255, 99, 132, 0.15);">
              <td><a href="https://arxiv.org/abs/2403.05530">Gemini-1.5-Pro</a></td><td>47.8</td></tr>

          <tr style="background-color: rgba(255, 99, 132, 0.15);">
              <td><a href="https://www.anthropic.com/news/claude-3-family">Claude-3-Opus</a></td><td>49.2</td></tr>

          <tr style="background-color: rgba(54, 162, 235, 0.15);">
              <td><a href="https://arxiv.org/abs/2002.08909">REALM</a></td><td>40.4</td></tr>

          <tr style="background-color: rgba(54, 162, 235, 0.15);">
              <td><a href="https://arxiv.org/abs/2004.04906">DPR</a></td><td>41.5</td></tr>

          <tr style="background-color: rgba(54, 162, 235, 0.15);">
              <td><a href="https://arxiv.org/abs/2005.114016">RAG</a></td><td>44.5</td></tr>

          <tr style="background-color: rgba(54, 162, 235, 0.15);">
              <td><a href="https://arxiv.org/abs/2112.04426">RETRO</a></td><td>45.5</td></tr>

          <tr style="background-color: rgba(54, 162, 235, 0.15);">
              <td><a href="https://arxiv.org/abs/2102.07033">RePAQ</a></td><td>47.8</td></tr>

          <tr style="background-color: rgba(54, 162, 235, 0.15);">
              <td><a href="https://arxiv.org/abs/2007.01282">FiD</a></td><td>51.4</td></tr>

          <tr style="background-color: rgba(54, 162, 235, 0.15);">
              <td><a href="https://arxiv.org/abs/2106.05346">EMDR</a></td><td>52.5</td></tr>

          <tr style="background-color: rgba(54, 162, 235, 0.15);">
              <td><a href="https://arxiv.org/abs/2208.03299">Atlas</a></td><td>64.0</td></tr>

          <tr style="background-color: rgba(75, 192, 192, 0.15);">
              <td><a href="https://arxiv.org/abs/2301.12652">REPLUG</a></td><td>45.5</td></tr>

          <tr style="background-color: rgba(75, 192, 192, 0.15);">
              <td>LongRAG (Gemini-1.5-Pro; Recall 4 units)</td><td>58.6</td></tr>

          <tr style="background-color: rgba(75, 192, 192, 0.15);">
              <td>LongRAG (GPT-4o; Recall 4 units)</td><td>62.7</td></tr>


          </tbody>
        </table>
        <p style="text-align: left;">
          The table shows the QA results on the NQ dataset. We compare the results with three groups of baselines: closed-book, which involves directly prompting
            state-of-the-art LLMs with 16-shot in-context examples; fully-supervised RAG, where the RAG framework is used and the model is fully supervised and trained
            on the training data; and No Fine-tuning RAG, which employs the RAG framework without any tuning
        </p>

      <hr class="dotted-line">

      <table class="table is-bordered is-three-fifths">
      <thead>
        <tr style="background-color: rgba(211, 211, 211, 0.5);">
          <th>Method</th>
          <th>EM(Exact Match Rate)</th>
        </tr>
      </thead>
      <tbody>

      <tr style="background-color: rgba(255, 99, 132, 0.15);">
          <td><a href="https://arxiv.org/abs/2303.08774">GPT-4-Turbo</a></td><td>42.4</td></tr>

      <tr style="background-color: rgba(255, 99, 132, 0.15);">
          <td><a href="https://arxiv.org/abs/2403.05530">Gemini-1.5-Pro</a></td><td>33.9</td></tr>

      <tr style="background-color: rgba(255, 99, 132, 0.15);">
          <td><a href="https://www.anthropic.com/news/claude-3-family">Claude-3-Opus</a></td><td>32.8</td></tr>

      <tr style="background-color: rgba(54, 162, 235, 0.15);">
          <td><a href="https://arxiv.org/abs/1905.05460">CogQA</a> </td><td>37.1</td></tr>

      <tr style="background-color: rgba(54, 162, 235, 0.15);">
          <td><a href="https://arxiv.org/abs/2002.10640">DrKIT</a></td><td>42.1</td></tr>

      <tr style="background-color: rgba(54, 162, 235, 0.15);">
          <td><a href="https://iclr.cc/virtual_2020/poster_r1eIiCNYwS.html">Transformer-XH</a></td><td>51.6</td></tr>

      <tr style="background-color: rgba(54, 162, 235, 0.15);">
          <td><a href="https://arxiv.org/abs/2204.04581">QAMAT+</a></td><td>57.6</td></tr>

      <tr style="background-color: rgba(54, 162, 235, 0.15);">
          <td><a href="https://arxiv.org/abs/1911.03631">HGN</a></td><td>59.7</td></tr>

      <tr style="background-color: rgba(54, 162, 235, 0.15);">
          <td><a href="https://arxiv.org/abs/1911.10470">PathRetriever</a></td><td>60.0</td></tr>

      <tr style="background-color: rgba(54, 162, 235, 0.15);">
          <td><a href="https://arxiv.org/abs/2012.15534">HopRetrieve</a></td><td>62.1</td></tr>

      <tr style="background-color: rgba(54, 162, 235, 0.15);">
          <td><a href="https://arxiv.org/abs/2009.12756">MDR</a></td><td>62.3</td></tr>

      <tr style="background-color: rgba(54, 162, 235, 0.15);">
          <td><a href="https://arxiv.org/abs/2012.15534">HopRetrieve-plus</a></td><td>66.5</td></tr>

      <tr style="background-color: rgba(54, 162, 235, 0.15);">
          <td><a href="https://arxiv.org/abs/2109.06747">AISO</a></td><td>68.1</td></tr>

      <tr style="background-color: rgba(54, 162, 235, 0.15);">
          <td><a href="https://arxiv.org/abs/2305.03130">COS</a></td><td>68.2</td></tr>

      <tr style="background-color: rgba(75, 192, 192, 0.15);">
          <td><a href="https://arxiv.org/abs/2212.14024">DSP</a></td><td>51.4</td></tr>

      <tr style="background-color: rgba(75, 192, 192, 0.15);">
          <td><a href="https://arxiv.org/abs/2205.12650">PromptRank</a></td><td>55.7</td></tr>

      <tr style="background-color: rgba(75, 192, 192, 0.15);">
          <td>LongRAG (Gemini-1.5-Pro; Recall 8 units)</td><td>57.5</td></tr>

      <tr style="background-color: rgba(75, 192, 192, 0.15);">
          <td>LongRAG (GPT-4o; Recall 8 units)</td><td>64.3</td></tr>

      </tbody>
    </table>
      <p style="text-align: left;">
          The table shows the QA results on the HotpotQA dev set. We compare the results with three groups of baselines: closed-book, which involves directly prompting
            state-of-the-art LLMs with 16-shot in-context examples; fully-supervised RAG, where the RAG framework is used and the model is fully supervised and trained
            on the training data; and No Fine-tuning RAG, which employs the RAG framework without any tuning
      </p>
      </div>
    </div>
  </div>


<!-- BibTex citation -->
<section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
        <h2 class="title">BibTeX</h2>
            Please kindly cite our paper if you use our code, data, models or results:
                <br><br>
                    <pre><code class="bibtex">
@article{jiang2024longrag
  title={LongRAG: Enhancing Retrieval-Augmented Generation with Long-context LLMs},
  author={Ziyan Jiang, Xueguang Ma, Wenhu Chen},
  journal={arXiv preprint arXiv:2406.15319},
  year={2024},
  url={https://arxiv.org/abs/2406.15319}
}
                    </code></pre>
    </div>
</section>
<!-- End BibTex citation -->

</body>

</html>
